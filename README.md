# ğŸ¤– HAI (HelpingAI) - Emotional Intelligence Training Pipeline

> A cutting-edge language model training pipeline focused on emotional intelligence and Gen Z communication style.

## ğŸŒŸ Overview

HAI is an advanced language model training pipeline designed to create emotionally intelligent AI that can communicate naturally with Gen Z users. Created by Abhay Koul (17-year-old developer), this project combines state-of-the-art language model architecture with specialized emotional intelligence training.

### ğŸ¯ Key Features

- ğŸ§  Advanced emotional intelligence training
- ğŸ’¬ Gen Z communication style integration
- ğŸŒ Multi-stage training pipeline (tokenizer, pretrain, emotional fine-tuning)
- ğŸ“Š Weights & Biases integration for experiment tracking
- ğŸ”„ Checkpoint and resume functionality
- ğŸ“ Comprehensive logging system
- ğŸ¨ Rich console output with progress tracking

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.8+ and CUDA-capable GPU recommended
python -m pip install -r requirements.txt
```

### Training Pipeline

```bash
# 1. Train tokenizer and prepare datasets
python scripts/train.py --stage tokenizer

# 2. Start pretraining
python scripts/train.py --stage pretrain

# 3. Emotional fine-tuning
python scripts/train.py --stage emotional_finetune
```

## ğŸ› ï¸ Technical Architecture

### Model Specifications
- Base Model: HAI-3.2B
- Tokenizer: BPE (Byte-Pair Encoding)
- Vocabulary Size: 32,768 tokens
- Training Stages:
  1. Tokenizer Training
  2. Pre-training
  3. Emotional Fine-tuning

### Datasets
- **Pretraining**:
  - Abhaykoul/test
  - JeanKaddour/minipile
  - OEvortex/EmotionalIntelligence-75k
  - OEvortex/Med-emo

- **Emotional Fine-tuning**:
  - OEvortex/EmotionalIntelligence-75k
  - OEvortex/Med-emo
  - OEvortex/HelpingAI2.5-English-openemotions
  - OEvortex/HelpingAI2.5-hinglish-openemotions
  - Custom self-cognition dataset

## ğŸ“‚ Project Structure

```
emotional_llm/
â”œâ”€â”€ configs/                 # Model and training configurations
â”‚   â”œâ”€â”€ pretrain-model.yaml
â”‚   â””â”€â”€ contrain-model.yaml
â”œâ”€â”€ scripts/                 # Training and dataset preparation scripts
â”‚   â”œâ”€â”€ train.py            # Main training pipeline
â”‚   â”œâ”€â”€ prepare_pretrain_dataset.py
â”‚   â”œâ”€â”€ prepare_contrain_dataset.py
â”‚   â””â”€â”€ cognition_dataset.py
â”œâ”€â”€ data/                    # Dataset storage
â”‚   â”œâ”€â”€ tokenizer/          # Tokenizer files
â”‚   â”œâ”€â”€ pretrain/           # Pretraining data
â”‚   â””â”€â”€ emotional/          # Emotional fine-tuning data
â””â”€â”€ output/                  # Training outputs
    â”œâ”€â”€ checkpoints/        # Model checkpoints
    â””â”€â”€ logs/               # Training logs
```

## âš™ï¸ Configuration

### Command Line Arguments

```bash
python scripts/train.py [--stage {tokenizer,pretrain,emotional_finetune}] 
                       [--data_dir DATA_DIR]
                       [--output_dir OUTPUT_DIR]
                       [--config_dir CONFIG_DIR]
                       [--resume]
                       [--disable_wandb]
                       [--debug]
```

### Configuration Files

- `pretrain-model.yaml`: Pretraining configuration
- `contrain-model.yaml`: Emotional fine-tuning configuration

## ğŸ“Š Training Monitoring

### Logs
- Training logs: `output/logs/hai_training_[timestamp].log`
- Error logs: `output/logs/hai_errors_[timestamp].log`
- Rich console output with progress bars
- Weights & Biases integration for experiment tracking

### Checkpoints
- Regular checkpoints during training
- Resume capability from latest checkpoint
- Final model saved with configurations

## ğŸ¯ Model Capabilities

- ğŸ—£ï¸ Natural Gen Z communication style
- ğŸ’­ Advanced emotional intelligence
- ğŸŒ Multilingual support (English & Hinglish)
- ğŸ¤ Contextual response generation
- ğŸ­ Emotional state detection

## ğŸ”’ Security & Privacy

- No sensitive data handling
- Configurable logging with opt-out options
- Debug mode for development
- Safe checkpoint management

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Author

**Abhay Koul**
- Age: 17
- Project: HelpingAI
- Focus: Emotional Intelligence in AI

## ğŸ™ Acknowledgments

- Thanks to the HuggingFace community
- Special thanks to all dataset contributors

---

<p align="center">Made with â¤ï¸ by Abhay Koul</p>
